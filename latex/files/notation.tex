We first provide an overview of the evolvability framework of
\cite{Valiant:2009-evolvability}. The description here contains differs slightly
from Valiant's orginal formulation (see also \cite{Feldman:2008-evolvability,
Feldman:2009-robustness, Valiant:2012-real, Kanade:2012-thesis}).

\subsection{Valiant's Evolvability Framework}

Let $X$ denote a set of instances, \eg $X = \reals^n$ or $X = \{0, 1\}^n$. We
assume that the length of representing each $x \in X$ is captured by the
parameter $n$. To avoid excessive notation, we will keep this size parameter
implicit in our description of the model. Let $D$ be a distribution over $X$.
Each $x \in X$ can be thought of as the description of an environmental setting,
the inputs to the circuit of an organism. $D$ denotes the distribution over the
possible environmental settings an organism may experience in a lifetime. Let $f
: X \rightarrow Y$ (typically $Y = \reals$ or $Y = \{0, 1\}$) denote the ideal
function, the (possibly hypothetical) best behaviour in each possible
environmental setting.

\subsubsection*{Representations}

A creature is a string representation that encodes an efficiently computable
function $r : X \rightarrow Y$, \ie there is an efficient Turing Machine that
given the description string $\langle r \rangle$ and $x \in X$, outputs $r(x)$.  

In this work, our focus is characterizing different evolutionary mechanisms
based on the complexity of representations used. The notion is similar in spirit
to the \emph{proper} vs. \emph{improper} learning question in computational
learning theory. The complexity of a representation is measured by the function
it computes.  Let $H : X \rightarrow Y$ be a class of functions. Let $R
\subseteq \{0, 1\}^*$.  We say that $R$ \emph{represents} $H$, if there is a map
$\sigma : R \rightarrow H$ and there exists an \emph{efficient} Turing machine
that given input $r \in R$ and $x \in X$, outputs $(\sigma(r))(x)$. Henceforth,
by abuse of notation we will use $r$ to denote both the representation and the
function it computes.

\subsubsection*{Evolutionary Algorithms}

The performance of a representation $r$ is measured using a loss function, $\ell
: Y \times Y \rightarrow \reals^+$, such that $\ell(y, y) = 0$. For a function
$g : X \rightarrow Y$, define the expected loss with respect to the ideal
function $f : X \rightarrow Y$, under distribution $D$, as $\loss_{f, D} = \E_{x
\sim D}[\ell(g(x), f(x))]$\footnote{This definition does not require the
expected loss to be bounded, but we'll mainly be interested in situations when
that is the case.}. The goal of evolution is to reach some representation $r^*$
such that $\loss_{f, D}(g) < \epsilon$. In the following discussion, we use the
notation: $f$ the ideal function, $\epsilon$ the target accuracy, $D$ the target
distribution over $X$ and $\loss_{f, D}(f)$ the expected loss function. \medskip \\
%
\noindent{\bf Mutator}: A mutator for a class of representations $R$, $\Mut$, is
a polynomial-time randomised Turing machine that takes as in put a
representation $r \in R$ and accuracy parameter $\epsilon$ and outputs a
multiset $\Neigh(r, \epsilon) \subseteq R$. \medskip \\
%
\noindent{\bf Selection}: (Natural) Selection is based on empirical performance
of each representation. Let $s : R \times [0, 1] \rightarrow \naturals$ be a
sample size function. First, the mutation algorithm, $\Mut(r, \epsilon)$ is run
to produce mutliset $\Neigh(r, \epsilon)$. Then an i.i.d. sample $\langle x_i
\rangle_{i=1}^s$ is drawn from the distribution $D$ over $X$, where $s = s(r,
\epsilon)$.  Denote the empirical performance of each $r^\prime \in \Neigh(r,
\epsilon) \cup \{r \}$ as
%
\[ \hat{\loss}_{f, D}(g) = \frac{1}{s}\sum_{i=1}^s \ell(r^\prime(x_i), f(x_i)) \]
%
Finally, let $t : R \times [0, 1] \rightarrow \reals$ be a tolerance function.
Two possible selection mechanisms are considered.
\begin{enumerate}
\item {\bf Selection based on beneficial and neutral mutations}: Let 
%
\[ \Bene = \{r^\prime \in \Neigh(r, \epsilon) ~|~ \hat{\loss}_{f, D}(r^\prime) \leq
\hat{\loss}_{f, D}(r) - t(r, \epsilon) \} \]  
%
denote the set of beneficial mutations and let 
%
\[ \Neut = \{r^\prime \in \Neigh(r, \epsilon) ~|~ |\hat{\loss}_{f, D}(r^\prime) -
\hat{\loss}_{f, D}(r)| <  t(r, \epsilon) \} \]
%
denote the neutral mutations, with respect to tolerance function $t$. Selection
operates as follows: if $\Bene \neq \emptyset$, $r^\prime$ is randomly selected
from $\Bene$ as the surviving creature at the next generation.  If $\Bene =
\emptyset$ and $\Neut \neq\emptyset$, then $r^\prime$ is selected randomly from
$\Neut$ as the surviving creature at the next generation.  Otherwise, $\bot$ is
produced signifying failure of evolution.
%
\item {\bf Selection based on optimisation}: Let $\widehat{\opt} =
\displaystyle\min_{r^\prime \in \Neigh(r, \epsilon)} \hat{\loss}_{f, D}(r^\prime)$.
If $\opt < \hat{\loss}_{f, D}(r) + t(r, \epsilon)$, then $\bot$ is produced
signifying failure of evolution.  Otherwise, let $\best = \{ r^\prime \in
\Neigh(r, \epsilon) ~|~ \hat{\loss}_{f, D}(r^\prime) \leq \opt + t(r, \epsilon) \}$.
Then $r^\prime$ is chosen from $\best$ randomly as the surviving creature at the
next generation.
\end{enumerate}

We denote a selection rule by $\Sel[R, \Mut, s, t]$, which may be one of the two
types described above. For $\Sel$ to be feasible we require that the size
function $s$ is polynomially (in $n$ and $1/\epsilon$) bounded and that there
exists polynomials $p_1(n, 1/\epsilon)$ and $p_2(n, 1/\epsilon)$, such that
$1/p_1(n, 1/\epsilon) \leq t(r, \epsilon) \leq p_2(n, 1/\epsilon)$ for every $r
\in R$. \medskip \\
%
\noindent {\bf Evolutionary Algorithm}: An evolutionary algorithm $\evalg$ is a
tuple $(R, \Mut, s, t, \Sel)$. When $\evalg$ is run starting from $r_0 \in R$
with respect to distribution $D$ over $X$, ideal function $f : X \rightarrow Y$,
loss function $\ell$ and parameter $\epsilon$, a sequence $r_0, r_1, r_2,
\ldots$ is produced, where $r_i$ is obtained from $r_{i-1}$ through application
of the selection rule $\Sel[R, \Mut, s, t]$. If $r_i = \bot$ for some $i$, we
consider evolution as halted and $r_j = \bot$ for $j > i$. We say that $\evalg$
succeeds at generation $g$, if $g$ is the smallest for which the expected loss,
$\loss_{f, D}(r_g) \leq \epsilon$.

\begin{definition}[Evolvability \cite{Valiant:2009-evolvability}] We say that a concept class $C$ is evolvable under a class of
distributions $\Dists$ using a representation class $R$, if there exists an
evolutionary algorithm $\evalg = (R, \Mut, s, t, \Sel)$, such that for every $D
\in \Dists$, every $f \in C$, and every $\epsilon > 0$, every $r_0 \in R$, with
probability at least $1 - \epsilon$, $\evalg$ run starting from $r_0$ with
respect to $f, D, \epsilon$, produces $r_g$ for which $\loss_{f, D}(r_g) <
\epsilon$. Furthermore, $g$ is bounded by a polynomial in $n, 1/\epsilon$.
\end{definition}

The definition presented above varies slightly from the definition of Valiant,
in the sense that we explicitly focus on the class of representations $R$ used
by the evolutionary algorithm. As discussed in the introduction, we focus on
concept classes where each function depends on \emph{few} (constant) input
variables\footnote{These functions have been referred to as juntas in the theory
literature. We avoid using this nomenclature as we restrict our attention to
specific functional forms, such as linear functions, with $k$ relevant
variables.}. 

\subsubsection{Strictly Beneficial Neighbourhoods}

Kanade \etal defined the notion of strictly beneficial neighbourhood
mutators~\cite{KVV:2010-drift}. At a high-level, these are mutation algorithms
that guarantee that at least one of the mutations produced will be (noticeably)
better than the current representation. It follows easily that if such a mutator
exists for some concept class $C$, then the class $C$ is
evolvable~\cite{KVV:2010-drift}. Formally, we can define.

\begin{definition}[Strictly Beneficial Neighbourhood Mutator] For a concept
class $C$, class of distributions $\Dists$, and $b : [0, 1] \rightarrow \reals$, we
say that a mutator $\Mut$ is a $b$-strictly beneficial neighbourhood mutator
over representation class $R$, if for every $r \in R$, $f \in C$, $D \in
\Dists$, and $\epsilon > 0$, if $\Neigh(r, \epsilon)$ is the output produced by
running the mutator $\Mut$ with $r$ and $\epsilon$ as inputs, then with
probability $1$, there exists $r^\prime \in \Neigh(r, \epsilon)$, such that
$\loss_{f, D}(r^\prime) < \loss_{f, D}(r)$.  \end{definition}

The purpose of defining strictly beneficial neighbourhood mutators is that
together with concentration bounds relating empirical loss to the true expected
loss, the existence of such mutators implies evolvability of the corresponding
class. Let $R$ be a class of representations, $C$ a concept class, $\Dists$ a
class of distributions and $\ell : Y \times Y \rightarrow \reals^+$ a loss
function such that for every $f \in C$, $D \in \Dists$ and $r \in R$, the
expected loss $\loss_{f, D}(r)$ is bounded and further that if $x_1, \ldots,
x_s$ are i.i.d. samples drawn from $D$, the following is true:
%
\[ \Pr\left[ |\frac{1}{s} \sum_{i=1}^s \ell(r(x_i), f(x_i)) - \loss_{f, D}(r)|
\geq \tau \right] \leq \exp(c_1 s^{c_2} \tau^{c_3}), \]
%
for absolute constants $c_1, c_2, c_3$. In such a case, we say that the loss
function with respect to $C$, $R$, $\Dists$ is bounded has exponential
concentration. 

\begin{theorem}[(Theorem 8~\cite{KVV:2010-drift})] \label{thm:benefit2evolve}
Let $C$ be a concept class, $\Dists$ a class of distributions. For a class of
representations, $R$, loss function, $\ell$, if there exists a strictly
beneficial neighbourhood mutator with benefit $b$, then $C$ is evolvable under
distributions from $\Dists$, with respect to loss function $\ell$ using the
representation class $R$.  \end{theorem}

The proof of the above Theorem essentially appears in \cite{KVV:2010}, who also
show that such an algorithm is robust to some modest (inverse polynomial) drift
in the target function. For the purpose of this paper, we will show the
existence of strictly beneficial neighbourhood mutators and appeal to
Theorem~\ref{thm:benefit2evolve}.

\subsection{Sparse Linear Functions} 

Our main result in this paper considers the class of sparse linear functions.
We represent a linear functions from $\reals^n \rightarrow \reals$ by a vector
$w \in \reals^n$, where $x \mapsto w \cdot x$.  For a vector $w \in \reals^n$,
$\lznorm{w}$ is the number of non-zero elements of $w$. 

For any $0 < l < u$ and integer $k$. Define the class of linear functions:
\[
\lin^k_{l, u} = \{ x \mapsto w \cdot x ~|~ \lznorm{w} \leq k, \forall i,
w_i = 0 \mbox{ or } l \leq |w_i| \leq u \}
\]
Thus, $\lin^k_{l, u}$ is the class of sparse linear functions, where the influence
of each variable is upper and lower bounded.

Let $D$ be a distribtion over $\reals^n$. For $w, w^\prime$, define the inner
product $\ip{w}{w^\prime}_D = \E_{x \sim D}[(w \cdot x) (w^\prime \cdot x)]$.
(Note that $w \cdot x = \sum_{i = 1}^n w_i x_i$ denotes the standard dot product
in $\reals^n$.) In the rest of this paper, we use $\ltwonorm{w}_D$ to denote
$\sqrt{\ip{w}{w})_D}$. (To avoid confusion, whenever necessary, we
will refer to the quantity $\sqrt{\sum_{i} w_i^2}$ explicitly if we mean the standard
Euclidean norm.) When the distribution $D$ is clear from context we will drop
the subscript.



\subsubsection{Banana Distributions}

We are mainly interested in the case when the instance space is $\reals^n$.
Also, we will focus on distributions $D$ over $\reals^n$ that are sub-Gaussian,
\ie for any $w \in \reals^n$ with $\ltwonorm{w} = 1$, if $X ~ D$, $\E[\exp((X
\cdot w) t)] \leq \exp(c^2t^2/2)$ for some constant $c$.  For a random variable
$X$, let $\var(X)$ denote the variance of $X$. Recall that for random variables
$X, Y$, the correlation, $\corr(X, Y) = \E[(X - \E[X]) (Y - E[Y])]/\sqrt{\var(X)
\var(Y)}$. We will work with the class of distributions, which we call zero-mean
bounded-variance sub-Gaussian $\Delta$-smooth distributions.

\vknote{This definition should be broken up and cleaned-up.} 

\begin{definition} A distribution $D$ over $\reals^n$ is $(c, \Delta)$-banana
distribution if the following hold:
\begin{enumerate}
\item $\E[X] = 0$
\item For $1 \leq i \leq n$, $\E[X_i^2] \leq 1$
\item $D$ is $c^2$ sub-Gaussian
\item $\E[\var(X_i ~|~ X_{-i})] \geq 2 \Delta^2$.
\end{enumerate}
\end{definition}

We will make repeated use for the following simple observation regarding this
class of distributions.

\begin{lemma} Let $D$ be a $(c, \Delta)$-smooth distribution. Then for all $i, j$,
$|\corr(X_i, X_j)| \leq 1 - \Delta^2$.
\end{lemma}
\begin{proof}

\end{proof}

For a distribution $D$ in the distribution class, we have the following useful
properties. 
\begin{lemma} Let $D$ be a zero-mean bounded-variance $c^2$-sub-Gaussian
$\Delta$-smooth distribution. Then the following are true:
\begin{enumerate}
\item For any $w \in \reals^n$, $w^2_i \leq \ip{w}{w}/\Delta^2$
\item For any $w \in \reals^n$, there exists $i$ such that $w^2_i \leq
\frac{\ip{w}{w}}{\lznorm{w}\Delta^2}$.
\end{enumerate}
\end{lemma}
\begin{proof}

\end{proof}
